\documentclass[a4paper,10pt]{article}
\usepackage{polski}
\usepackage[utf8]{inputenc}

%opening
\title{Raport z zadania z pracowni z przedmiotu ,,Eksploracja danych''}

\date{\today}
\author{Joanna Biega, Paweł Kalinowski, Piotr Sobczyk}

\begin{document}

\maketitle
\section{Wstęp}

\subsection{Cel zadania i zarys rozwiązania}
Celem projektu była analiza finansowych szeregów czasowych za pomocą reguł asocjacyjnych. W fazie wstępnej przeprowadzona została dyskretyzacja danych, następnie
użyto algorytmu apriori i na podstawie analizy wskaźników takich jak confidence, lift czy leverage wybrano trzy reguły, które niosą ze sobą najbardziej
nietrywialna informację.

\subsection{Dane}
Dane zawierały notowania spółki Google na amerykańskiej giełdzie 
NASDAQ, zawierają one informacje z każdego dnia dotyczące cen akcji tej firmy. Policzone zostały zwroty dzienne według wzoru: $R_t = \frac{S_t}{S_{t-1}}$.
Na potrzeby projektu zwroty rozważano w skali logarytmicznej, jej wybór wynika z potrzeby symetryzacji danych. 
Następnie zostały rozważone dwa sposoby dyskretyzacji danych. Pierwszy to podział na 5 grup w zależności od przedziału kwantylowego, 
np. danej z przedziału kwantylowego (0.2, 0.4) będzie przyporządkowana liczba -1, a danej mieszczącej się powyżej kwantyla 0.8 – liczba 2.
Drugi podział opierał się na wartościach bezwzględnych: dane w odległości mniejszej niż jedno odchylenie standardowe od średniej są zaklasyfikowane 
jako 0, liczbę z przedziału $(\mu - 2 \cdot \sigma, \mu - \sigma)$ zmienia się na -1 itd.
Dane przygotowane do ostatecznej analizy składały się zatem z ciągu liczb całkowitych reprezentującego szereg czasowy odpowiadający logarytmom ze zwrotów ceny akcji.

\section{Używane algorytmy}
W celu analizy zależności w szeregu czasowym wykorzystane zostały reguły asocjacyjne i algorytm apriori. W tym celu cały szereg czasowy traktowany był
 jako zbiór wielu, przesuniętych o jedną jednostkę czasu, podszeregów długości $n$. Są to odpowiedniki transakcji w klasycznym algorytmie apriori. 
Konkretne reguły asocjacyjne np. $(1,0,0)$ były odszukiwane w transakcjach. W przeciwieństwie do klasycznego algorytmu kolejność liczb całkowitych w tych
zbiorach była ustalona, ponieważ domyślnie były one indeksowane czasem.

\section{Wyniki}
Wśród reguł wybierane były tylko te o supporcie większym niż 0,09. Ograniczenie to w znaczący sposób wpływa na znalezione reguły: będą one dość krótkie, 
a więc znalezione ,,zasady działania rynku'' są krótkookresowe. Podejście to ma uzasadnienie, ponieważ w dłuższym czasie na zmiany kursów wpływają 
choćby trendy, ze względu na które zbiór uczący nie jest jednolity.

Następnie wybrane zostały reguły o najbardziej odległym od 0 leverage – czyli te, które są statystycznie istotne, a nie dziełem przypadku, 
wzięte zostały pod uwagę także wartości confidence i lift, które też mówią o istotności reguły i prawdopodobieństwie jej wystąpienia. 
Ostatecznie wybrano 3 najlepsze reguły, dla długości transakcji równej 10, zaprezentowane w tabelach \ref{tab:k1} i \ref{tab:k2}.

Reguły dotyczą niewielkich zmian (mało odległych od średniej), bo tylko one wstępują dość często aby mieć support większy od ustalonego minimum.
Nie znaleziono żadnych reguł o dodatnim leverege, a więc takich w których wystąpienie następnika jest bardziej prawdopodobne dzięku zaobserwowaniu poprzednika. Wskazuje to na trudności w modelowaniu finansowych szeregów czasowych. Uzyskana wiedza nie jest ,,pozytywna'', nie pozwala na przewidywanie zachowań rynku. Z przykładowych wielkości podanych w tabelach widać, że ta własność nie zależy od sposobu dyskretyzacji danych.

Uzyskane reguły mają bardzo naturalną interpretację. I tak na przykład z tabeli \ref{tab:k1} wnioskuje się, że szybki wzrost ceny akcji z reguły $(1,0)$ powoduje zmniejszenie się szansy stabilnego zachowania ceny następnego dnia. Z reguły $(-1,0,1)$ wynika, że jeśli cena akcji poszło mocno w dół, kolejnego dnia była stabilna
to szansa na duży wzrost następnego dnia jest mniejsza niż wynikałoby z ogólnej czestości występowania dużych wzrostów.

\begin{center}
\begin{table}
\centering
\caption{Zbiór reguł zawierających najmniej trywialną wiedzę. Metoda dyskretyzacji danych odchyleniowa.}
\begin{tabular}{|l|l|l|l|l|} 
\hline
\bf{Reguła} & \bf{Confidence} & \bf{Support} & \bf{Leverage} & \bf{Lift} \\ \hline
(1,0) & 0.73 & 0.6 & -0.2 & 0.75 \\ \hline
(-1,0,1) & 0.25 & 0.15 & -0.34 & 0.3 \\ \hline
(1,-1) & 0.31 & 0.25 & -0.43 & 0.38 \\ \hline
\end{tabular}
\label{tab:k1}
\end{table}
\end{center}


\begin{center}
\begin{table}
\centering
\caption{Zbiór reguł zawierających najmniej trywialną wiedzę. Metoda dyskretyzacji danych kwantylową.}
\begin{tabular}{|l|l|l|l|l|} 
\hline
\bf{Reguła} & \bf{Confidence} & \bf{Support} & \bf{Leverage} & \bf{Lift} \\ \hline
(0,-1) & 0.42 & 0.35 & -0.37 & 0.49  \\ \hline
(1,-1) & 0.38 & 0.33 & -0.41 & 0.45 \\ \hline
(-1,2) & 0.22 & 0.2 & -0.5 & 0.28 \\ \hline
\end{tabular}
\label{tab:k2}
\end{table}
\end{center}

\section{Podsumowanie}

Uzyskane wyniki pozwalają na wysunięcie kilku wniosków. Po pierwsze, metoda reguł asocjacyjnych nie daje wiedzy, która pozwalałaby przewidywać zmianę notowań
giełdowych. Daje jednak ,,wiedzę negatywną'' dotyczącą tego, jakie zmiany są mało prawdopodobne (niskie confidence), lub stosunkowo rzadko występujące w określonej konfiguracji w porównaniu z częstościami występowania następnika i poprzednika (ujemne leverage). Po drugie, wiele z uzyskanych reguł cechują bardzo podobne wartości wskaźników, co rodzi problem z wyborem tych najbardziej 
nietrywialnych. Po trzecie, długości reguł uzyskanych metodą reguł asocjacyjnych są niskie. Przy ustalonej długości transakcji 10 i minimalnymi supporcie 0.09 są to szeregi czasowe dwu lub trzyelementowe. Reasumując analiza finansowych szeregów czasowych metodą reguł asocjacyjnych daje nietrywialną wiedzę dotyczącą krótkich okresów.

\end{document}
